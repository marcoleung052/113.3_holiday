# ä¸­æ–‡ GPT-2 æ–‡æœ¬è£œå…¨å¯¦é©—å ±å‘Š

æœ¬å°ˆæ¡ˆæ—¨åœ¨æ¯”è¼ƒå¤šç¨®ä¸­æ–‡ GPT-2 æ¨¡å‹åœ¨æ–‡æœ¬è£œå…¨ä»»å‹™ä¸­çš„è¡¨ç¾ï¼Œä¸¦åˆ†æä¸åŒ `max_length` è¨­å®šå°è£œå…¨çµæœçš„å½±éŸ¿ã€‚

## ä½¿ç”¨æ–¹å¼ç¸½è¦½
### 1. CLI è£œå…¨
å¿«é€Ÿå‘½ä»¤åˆ—è£œå…¨ï¼Œé©åˆæ‰¹æ¬¡è™•ç†æˆ–ç°¡æ˜“æ¸¬è©¦ã€‚
```python
input_text = "ä»–å€‘"
inputids = tokenizer.encode(inputtext, return_tensors="pt")

output = model.generate(
    input_ids,
    max_length=20,
    numreturnsequences=3,
    do_sample=True,
    top_k=50,
    temperature=0.9,
    padtokenid=tokenizer.padtokenid
)

print(tokenizer.decode(output[0], skipspecialtokens=True))
```

### 2. Gradio Web ä»‹é¢
æä¾›å³æ™‚è£œå…¨å»ºè­°ï¼Œé©åˆå±•ç¤ºèˆ‡äº’å‹•ã€‚
```python
def autocomplete(text):
    inputids = tokenizer.encode(text, returntensors="pt")
    output = model.generate(
        input_ids,
        max_length=20,
        numreturnsequences=1,
        norepeatngram_size=2,
        top_k=50,
        temperature=1.0,
        do_sample=True,
        padtokenid=tokenizer.eostokenid
    )
    return [tokenizer.decode(o, skipspecialtokens=True) for o in output]

gr.Interface(
    fn=autocomplete,
    inputs="text",
    outputs=gr.Textbox(type="text", label="Completions", lines=3),
    live=True
).launch()
```
### 3. Flask API è£œå…¨

æä¾› RESTful APIï¼Œå¯æ•´åˆè‡³å‰ç«¯æˆ–å…¶ä»–ç³»çµ±ã€‚

```python
@app.route("/generate", methods=["POST"])
def generate():
    data = request.json
    input_text = data.get("text", "")
    inputids = tokenizer.encode(inputtext, return_tensors="pt")
    output = model.generate(
        input_ids,
        maxlength=len(inputids[0]) + 50,
        do_sample=True,
        top_k=50,
        temperature=0.9,
        padtokenid=tokenizer.padtokenid
    )
    result = tokenizer.decode(output[0], skipspecialtokens=True)
    return jsonify({"result": result})
```

### 4. Flask é¸å¥äº’å‹•è£œå…¨ï¼ˆå« log-probability è©•åˆ†ï¼‰

æä¾›å¤šå€‹è£œå…¨é¸é …ä¸¦è©•åˆ†ï¼Œä½¿ç”¨è€…å¯é€å¥é¸æ“‡æ¥çºŒå…§å®¹ã€‚

```python
def generateoptionswithscores(prompt, numoptions=5):
    inputids = tokenizer.encode(prompt, returntensors="pt")
    outputs = model.generate(
        input_ids,
        maxlength=len(inputids[0]) + 50,
        numreturnsequences=num_options,
        do_sample=True,
        top_k=50,
        temperature=0.9,
        padtokenid=tokenizer.padtokenid,
        output_scores=True,
        returndictin_generate=True
    )

    results = []
    for sequence, score_set in zip(outputs.sequences, outputs.scores):
        logprobs = [score.max().item() for score in score_set]
        total_score = sum(logprobs)
        text = tokenizer.decode(sequence, skipspecialtokens=True)
        results.append((text, total_score))

    return results
```

äº’å‹•æµç¨‹ï¼š

```python
while True:
    text = input("è«‹è¼¸å…¥æ–‡å­—ï¼ˆæŒ‰ Enter çµæŸï¼‰ï¼š")
    if not text.strip():
        break
    completions = generateoptionswith_scores(text)
    print("GPT-2 è£œå…¨å»ºè­°ï¼š")
    for i, c in enumerate(completions):
        print(f"{i+1}. {c}")
    print("-" * 40)
```





## è£œå…¨æ–¹æ³•èˆ‡æ¯”è¼ƒ
æˆ‘å€‘é‡å°è£œå…¨æ–¹æ³•é€²è¡Œå¯¦é©—ï¼Œè§€å¯Ÿè£œå…¨çµæœçš„è®ŠåŒ–ï¼š
| æŠ€è¡“æ–¹å¼ | å„ªé» | ç¼ºé» |
| ---- | ---- | ---- |
| CLI å–®æ¬¡è£œå…¨ (å‘½ä»¤åˆ—) | - å¯«æ³•ç°¡å–®ã€é©åˆå¿«é€Ÿæ¸¬è©¦æ¨¡å‹<br>- æ”¯æ´å¤šå€‹å¥å­ç”Ÿæˆ<br>- å®¹æ˜“åµŒå…¥åˆ°å…¶ä»–æµç¨‹ä¸­ | - ç„¡äº’å‹•æ€§ï¼Œåªèƒ½ä¸€æ¬¡æ€§ç”Ÿæˆ<br>- ç„¡å€™é¸é¸é …æˆ–ä¿¡å¿ƒåˆ†æ•¸<br>- ç„¡æ³•æŒçºŒæ¥çºŒæˆ–æ“´å±•èªå¢ƒ |
| Gradio å³æ™‚ç¶²é è£œå…¨ | - ä½¿ç”¨è€…ä»‹é¢ç›´è§€ã€æ˜“ä¸Šæ‰‹<br>- å³æ™‚è£œå…¨ã€è‡ªå‹•æ›´æ–°<br>- å¯æœ¬åœ°æˆ–é ç«¯éƒ¨ç½² | - åƒ…ç”¢ç”Ÿå–®å¥ï¼Œäº’å‹•æ€§ä½<br>- ç„¡é¸é …é¸æ“‡ã€ç„¡æ¥å¥åŠŸèƒ½<br>- è¼¸å‡ºé•·åº¦èˆ‡æ§åˆ¶ä¸å¤ å½ˆæ€§ |
| Flask API + CLI è£œå…¨è¿´åœˆ | - æœ‰äº’å‹•è¼¸å…¥ã€é¸æ“‡èˆ‡çºŒå¥èƒ½åŠ›<br>- é¡¯ç¤º log-prob ä¿¡å¿ƒåˆ†æ•¸<br>- å¯æ‹“å±•æˆ Web API æˆ– GUI å·¥å…· | - ä½¿ç”¨é–€æª»ç¨é«˜ï¼ˆéœ€ç†è§£ CLI æµç¨‹ï¼‰<br>- æ²’æœ‰åœ–å½¢ç•Œé¢ï¼ˆéœ€æ‰‹å‹•å»º GUIï¼‰<br>- çµæœç„¡æ³•ç›´æ¥å„²å­˜æˆ–è¤‡è£½åˆ†äº« |

## max_length å¯¦æ¸¬åˆ†æ
æˆ‘å€‘é‡å° max_length åƒæ•¸é€²è¡Œå¯¦é©—ï¼Œè§€å¯Ÿè£œå…¨çµæœçš„è®ŠåŒ–ï¼š
å¯¦é©—è¨­å®š
- é–‹é ­å¥å­ï¼šã€Œä»–å€‘ã€
- æ¸¬è©¦ max_lengthï¼š20ã€50
  
çµæœæ‘˜è¦
| é•·åº¦è¨­å®š | è¼¸å‡ºé¢¨æ ¼ | æµæš¢åº¦ | çµå°¾ä¸­æ–·æ„Ÿ |
| :----: | :----- | :----- | :----- |
| max_length = 20 | é€šå¸¸åƒ…ä¸€å…©å¥ï¼Œåå£èª | ä¸­ç­‰ï¼ˆéœ€è‰¯å¥½æ¥å¥ï¼‰ | çµå°¾é€šå¸¸çªç„¶çµæŸæˆ–ç¼ºè© |
| max_length = 50 | å¯æ§‹æˆæ®µè½ï¼Œæœ‰æƒ…å¢ƒ | é«˜ï¼ˆèªæ„é€£è²«ï¼‰ | çµå°¾ç•¥çªå…€ |

è£œå…¨ç¯„ä¾‹ï¼ˆmax_length=50ï¼‰
ä»–å€‘çš„èœå‘³é“å’Œæ•¸æ“šéƒ½å¾ˆå¥½ï¼Œæœå‹™æ…‹åº¦ä¹Ÿéƒ½æŒºå¥½ï¼Œèœåƒ¹ä¹Ÿåˆç†ï¼Œæ‰€ä»¥ç”Ÿæ„å¾ˆå¥½ï¼Œé©åˆå…¬å¸é›†é«”æ´»å‹•ï¼Œå…¬å¸è«‹å®¢ã€‚

## æ¨¡å‹æ¯”è¼ƒ
æˆ‘å€‘æ¸¬è©¦äº†ä»¥ä¸‹å¹¾å€‹ä¸­æ–‡ GPT-2 æ¨¡å‹ï¼š
## ğŸ¤– æ¨¡å‹æ¯”è¼ƒ

| æ¨¡å‹åç¨± | é¢¨æ ¼å‚¾å‘ | ç°¡ç¹é«”æ”¯æ´ | å“è³ªè©•ä¼° | å‚™è¨» |
|---|---|---|---|---|
| åŸå§‹ GPT-2 ä¸­æ–‡ | æ··äº‚ã€å£èªä¸é€š | ä¸èƒ½ç©©å®šè™•ç†ç¹é«”ï¼Œæ˜“å‡ºéŒ¯ | â˜… | åå¯¦é©—ç”¨é€”ï¼Œéå¯¦éš›å ´æ™¯æ¨è–¦ |
| ckiplab/gpt2-base-chinese | æ¸…æ™°åˆ†è©ã€é¢¨æ ¼åˆ¶å¼ | å¼·ç¹é«”æ”¯æ´ï¼Œåˆ†è©è¼ƒç©©å®š | â˜…â˜… | é©åˆç¹é«”ä»»å‹™ï¼Œè¼¸å‡ºæ¯”è¼ƒåå‘æ”¿æ²» |
| IDEA-CCNL/Wenzhong-GPT2-110M | æ•˜äº‹æ„Ÿå¼·ï¼Œæœ‰å‰µæ„ä½†èªæ³•ä¸ç©©å®š | åç°¡é«”ï¼Œç¹é«”è¼¸å…¥æœƒè½‰å¯«æˆ–å¤±æº– | â˜…â˜…â˜… | é©åˆæ¨¡æ“¬å£èªæˆ–æƒ…å¢ƒå¼ç”Ÿæˆ|
| uer/gpt2-chinese-cluecorpussmall | å£èªè‡ªç„¶ã€è¿‘ç¶²æ°‘èªè¨€ | åç¹é«”ï¼Œä½†è¼¸å‡ºæœ‰æ™‚å€™æœƒå‡ºç¾ç°¡é«” | â˜…â˜…â˜… | ç¾é£Ÿè©•è«–é¢¨æ ¼æ˜é¡¯ï¼Œå¯¦ç”¨æ€§ä½³ |

## ç’°å¢ƒéœ€æ±‚
